

100%|██████████| 5/5 [00:07<00:00,  1.42s/it]
1it [00:00,  2.24it/s]
{'prediction': tensor([0.1658, 2.0214, 1.0864, 1.9437], device='cuda:0'), 'true': [tensor([ 22., 116.,  55., 154.], device='cuda:0')]}
{'prediction': tensor([0.1691, 2.0198, 1.0887, 1.9413], device='cuda:0'), 'true': [tensor([ 48.,  98.,  84., 142.], device='cuda:0')]}
{'prediction': tensor([0.1673, 1.9539, 1.0601, 1.8764], device='cuda:0'), 'true': [tensor([ 46., 106.,  77., 147.], device='cuda:0')]}

5it [00:02,  2.12it/s]
{'prediction': tensor([0.1601, 1.9196, 1.0394, 1.8470], device='cuda:0'), 'true': [tensor([ 13., 108.,  46., 145.], device='cuda:0')]}
{'prediction': tensor([0.1669, 2.0264, 1.0893, 1.9494], device='cuda:0'), 'true': [tensor([ 31.,  94.,  68., 133.], device='cuda:0')]}
{'prediction': tensor([0.1612, 1.9242, 1.0420, 1.8504], device='cuda:0'), 'true': [tensor([ 25., 115.,  60., 153.], device='cuda:0')]}
Saving the best model
7it [00:02,  2.33it/s]
C:\Users\0005h\OneDrive\Documents\programming\pycharm\Bachelor_thesis\train_bbox.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.stack((torch.tensor(outputs[0], dtype=torch.uint8), torch.tensor(bboxes[0], dtype=torch.uint8)))))

100%|██████████| 5/5 [00:04<00:00,  1.08it/s]
0it [00:00, ?it/s]
{'prediction': tensor([-0.2962,  7.1556,  3.5597,  5.6755], device='cuda:0'), 'true': [tensor([ 55., 114.,  84., 147.], device='cuda:0')]}

3it [00:02,  1.39it/s]
{'prediction': tensor([-0.2923,  7.0841,  3.5208,  5.6107], device='cuda:0'), 'true': [tensor([ 31., 108.,  63., 148.], device='cuda:0')]}

4it [00:03,  1.24it/s]